{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries, modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "batch_size = 100\n",
    "image_shape = [28, 28, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read32(bytestream):\n",
    "    dt = np.dtype(np.uint32).newbyteorder('>')\n",
    "    return np.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
    "\n",
    "def load_train_data():\n",
    "    mnist_dir = '/mnt/cube/f1fan/data/mnist'\n",
    "    train_image_path = os.path.join(mnist_dir, 'train-images-idx3-ubyte.gz')\n",
    "    train_label_path = os.path.join(mnist_dir, 'train-labels-idx1-ubyte.gz')\n",
    "\n",
    "    with gzip.open(train_image_path) as image_stream, gzip.open(train_label_path) as label_stream:\n",
    "        magic_image, magic_label = read32(image_stream), read32(label_stream)\n",
    "        if magic_image != 2051 or magic_label != 2049:\n",
    "            raise ValueError('Invalid magic number')\n",
    "\n",
    "        image_count, label_count = read32(image_stream), read32(label_stream)\n",
    "        row_count = read32(image_stream)\n",
    "        col_count = read32(image_stream)\n",
    "\n",
    "        label_buffer = label_stream.read(label_count)\n",
    "        train_labels = np.frombuffer(label_buffer, dtype=np.uint8)\n",
    "\n",
    "        image_buffer = image_stream.read(row_count * col_count * image_count)\n",
    "        train_images = np.frombuffer(image_buffer, dtype=np.uint8)\n",
    "        train_images = train_images.reshape(image_count, row_count, col_count, 1)\n",
    "\n",
    "        return train_images, train_labels\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    mnist_dir = '/mnt/cube/f1fan/data/mnist'\n",
    "    test_image_path = os.path.join(mnist_dir, 't10k-images-idx3-ubyte.gz')\n",
    "    test_label_path = os.path.join(mnist_dir, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    with gzip.open(test_image_path) as image_stream, gzip.open(test_label_path) as label_stream:\n",
    "        magic_image, magic_label = read32(image_stream), read32(label_stream)\n",
    "        if magic_image != 2051 or magic_label != 2049:\n",
    "            raise ValueError('Invalid magic number')\n",
    "\n",
    "        image_count, label_count = read32(image_stream), read32(label_stream)\n",
    "        row_count = read32(image_stream)\n",
    "        col_count = read32(image_stream)\n",
    "\n",
    "        label_buffer = label_stream.read(label_count)\n",
    "        test_labels = np.frombuffer(label_buffer, dtype=np.uint8)\n",
    "\n",
    "        image_buffer = image_stream.read(row_count * col_count * image_count)\n",
    "        test_images = np.frombuffer(image_buffer, dtype=np.uint8)\n",
    "        test_images = test_images.reshape(image_count, row_count, col_count, 1)\n",
    "\n",
    "        return test_images, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(scope, input_layer, output_dim, use_bias=True,\n",
    "            filter_size=3, strides=[1, 1, 1, 1]):\n",
    "    input_dim = input_layer.get_shape().as_list()[-1]\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        conv_filter = tf.get_variable(\n",
    "            'conv_weight',\n",
    "            shape = [filter_size, filter_size, input_dim, output_dim],\n",
    "            dtype = tf.float32,\n",
    "            initializer = tf.contrib.layers.variance_scaling_initializer(),\n",
    "            regularizer = tf.contrib.layers.l2_regularizer(scale=0.0002)\n",
    "        )\n",
    "        conv = tf.nn.conv2d(input_layer, conv_filter, strides, 'SAME')\n",
    "\n",
    "        if use_bias:\n",
    "            bias = tf.get_variable(\n",
    "                'conv_bias',\n",
    "                shape = [output_dim],\n",
    "                dtype = tf.float32,\n",
    "                initializer = tf.constant_initializer(0.0)\n",
    "            )\n",
    "\n",
    "            output_layer = tf.nn.bias_add(conv, bias)\n",
    "            output_layer = tf.reshape(output_layer, conv.get_shape())\n",
    "        else:\n",
    "            output_layer = conv\n",
    "\n",
    "        return output_layer\n",
    "\n",
    "def batch_norm(scope, input_layer, is_training, reuse):\n",
    "\n",
    "    output_layer = tf.contrib.layers.batch_norm(\n",
    "        input_layer,\n",
    "        decay = 0.9,\n",
    "        scale = True,\n",
    "        epsilon = 1e-5,\n",
    "        is_training = is_training,\n",
    "        reuse = reuse,\n",
    "        scope = scope\n",
    "    )\n",
    "\n",
    "    '''\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        input_dim = input_layer.get_shape().as_list()[-1]\n",
    "        mean, variance = tf.nn.moments(input_layer, [0, 1, 2])\n",
    "        beta = tf.get_variable(\n",
    "            'bn_beta',\n",
    "            shape = [input_dim],\n",
    "            dtype = tf.float32,\n",
    "            initializer = tf.constant_initializer(0.0)\n",
    "        )\n",
    "        gamma = tf.get_variable(\n",
    "            'bn_gamma',\n",
    "            shape = [input_dim],\n",
    "            dtype = tf.float32,\n",
    "            initializer = tf.constant_initializer(1.0)\n",
    "        )\n",
    "\n",
    "        output_layer = tf.nn.batch_normalization(input_layer, mean, variance,\n",
    "                                                 beta, gamma, 0.00001)\n",
    "    '''\n",
    "    return output_layer\n",
    "\n",
    "def lrelu(input_layer, leak=0.2):\n",
    "    #output_layer = tf.nn.relu(input_layer)\n",
    "    output_layer = tf.maximum(input_layer, leak * input_layer)\n",
    "    #output_layer = input_layer * tf.sigmoid(input_layer)\n",
    "    return output_layer\n",
    "\n",
    "def fully_connected(scope, input_layer, output_dim):\n",
    "    input_dim = input_layer.get_shape().as_list()[-1]\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        fc_weight = tf.get_variable(\n",
    "            'fc_weight',\n",
    "            shape = [input_dim, output_dim],\n",
    "            dtype = tf.float32,\n",
    "            initializer = tf.contrib.layers.variance_scaling_initializer(),\n",
    "            regularizer = tf.contrib.layers.l2_regularizer(scale=0.0002)            \n",
    "        )\n",
    "\n",
    "        fc_bias = tf.get_variable(\n",
    "            'fc_bias',\n",
    "            shape = [output_dim],\n",
    "            dtype = tf.float32,\n",
    "            initializer = tf.constant_initializer(0.0)\n",
    "        )\n",
    "\n",
    "        output_layer = tf.matmul(input_layer, fc_weight) + fc_bias\n",
    "\n",
    "        return output_layer\n",
    "\n",
    "def avg_pool(scope, input_layer, ksize=None, strides=[1, 2, 2, 1]):\n",
    "    if ksize is None:\n",
    "        ksize = strides\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        output_layer = tf.nn.avg_pool(input_layer, ksize, strides, 'VALID')\n",
    "        return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_image, is_training, reuse):\n",
    "    with tf.variable_scope('models', reuse=reuse):\n",
    "        filter_dim = 64\n",
    "        batch_size = images.get_shape().as_list()[0]\n",
    "\n",
    "        h0_conv = conv2d('h0_conv', images, filter_dim, filter_size=5, strides=[1, 2, 2, 1])\n",
    "        h0 = lrelu(h0_conv)\n",
    "\n",
    "        h1_conv = conv2d('h1_conv', h0, filter_dim * 2, filter_size=5, strides=[1, 2, 2, 1])\n",
    "        h1_bn = batch_norm('h1_bn', h1_conv, is_training, reuse)\n",
    "        h1 = lrelu(h1_bn)\n",
    "\n",
    "        h2_conv = conv2d('h2_conv', h1, filter_dim * 4, filter_size=5, strides=[1, 2, 2, 1])\n",
    "        h2_bn = batch_norm('h2_bn', h2_conv, is_training, reuse)\n",
    "        h2 = lrelu(h2_bn)\n",
    "\n",
    "        h3_conv = conv2d('h3_conv', h2, filter_dim * 8, filter_size=5, strides=[1, 2, 2, 1])\n",
    "        h3_bn = batch_norm('h3_bn', h3_conv, is_training, reuse)\n",
    "        h3 = lrelu(h3_bn)\n",
    "\n",
    "        fc = fully_connected('fc', tf.reshape(h3, [batch_size, -1]), 10)\n",
    "        return tf.nn.softmax(fc), fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_train_op(batch_size, image_shape):\n",
    "    [height, width, channels] = image_shape\n",
    "    batch_shape = [batch_size, height, width, channels]\n",
    "    train_image_placeholder = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape = batch_shape,\n",
    "        name = 'train_images'\n",
    "    )\n",
    "    train_label_placeholder = tf.placeholder(\n",
    "        tf.int32,\n",
    "        shape = [batch_size, ],\n",
    "        name = 'train_labels'\n",
    "    )\n",
    "    \n",
    "    prob, logits = build_modelk(train_image_placeholder, True, False)\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels = self.train_label_placeholder,\n",
    "        logits = logits\n",
    "    )\n",
    "    \n",
    "    train_step = tf.Variable(initial_value=0, trainable=False)\n",
    "    prediction = tf.equal(tf.cast(tf.argmax(prob, axis=1), tf.int32), train_label_placeholder)\n",
    "    train_loss = tf.reduce_mean(loss)\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "\n",
    "    train_vars = [x for x in tf.trainable_variables() if 'models' in x.name]\n",
    "    optimizer = tf.train.AdamOptimizer(0.01)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(train_loss, global_step=train_step, var_list=train_vars)\n",
    "    \n",
    "    return train_image_placeholder, train_label_placeholder, train_loss, train_accuracy, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_test_op(batch_size, image_shape):\n",
    "    [height, width, channels] = image_shape\n",
    "    batch_shape = [batch_size, height, width, channels]\n",
    "    test_image_placeholder = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape = batch_shape,\n",
    "        name = 'test_images'\n",
    "    )\n",
    "    test_label_placeholder = tf.placeholder(\n",
    "        tf.int32,\n",
    "        shape = [train_batch_size, ],\n",
    "        name = 'test_labels'\n",
    "    )\n",
    "    \n",
    "    prob, logits = build_modelk(train_image_placeholder, True, False)\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels = self.train_label_placeholder,\n",
    "        logits = logits\n",
    "    )\n",
    "    prediction = tf.equal(tf.cast(tf.argmax(prob, axis=1), tf.int32), test_label_placeholder)\n",
    "    test_loss = tf.reduce_mean(loss)\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "    \n",
    "    return test_image_placeholder, test_label_placeholder, test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(sess):\n",
    "    train_images, train_labels = load_train_data()\n",
    "    test_images, test_labels = load_test_data()\n",
    "    \n",
    "    train_image_placeholder, train_label_placeholder, train_loss, train_accuracy, train_op = build_train_op(batch_size, image_shape)\n",
    "    test_image_placeholder, test_label_placeholder, test_loss, test_accuracy = build_test_op(batch_size, image_shape)\n",
    "\n",
    "    all_initializer_op = tf.global_variables_initializer()\n",
    "    sess.run(all_initializer_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "        with tf.device('/gpu:0'):\n",
    "            with tf.Session(config=config) as sess:\n",
    "                with tf.variable_scope('SimpleCNN', reuse=None):\n",
    "                    main(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
